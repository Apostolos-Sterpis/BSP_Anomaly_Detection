{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef2b0f1-59ee-409e-8131-3a5f638f44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apostolos_sterpis/BSP_Anomaly_Detection/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\") / \"src\"))\n",
    "\n",
    "from utils import config\n",
    "from utils.io import load_cleaned, load_method_ready, results_dir, append_csv_row, save_json\n",
    "from utils.evaluation import compute_binary_metrics\n",
    "from utils.plotting import plot_signal, plot_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9880db4f-c3cf-43ff-8e70-b59edf2cbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Windows, Mapping and Model\n",
    "\n",
    "def windows_from_starts(series: np.ndarray, starts: np.ndarray, win_size: int) -> np.ndarray:\n",
    "    \"\"\"Build windows (n, win_size, 1) using the exact start indices.\"\"\"\n",
    "    series = np.asarray(series).reshape(-1)\n",
    "    w = np.lib.stride_tricks.sliding_window_view(series, win_size)  # (n_possible, win_size)\n",
    "    X = w[starts]  # (n_windows, win_size)\n",
    "    return X[..., None].astype(np.float32)  # (n_windows, win_size, 1)\n",
    "\n",
    "\n",
    "def windows_scores_to_point_scores_max(\n",
    "    win_starts_local: np.ndarray,\n",
    "    win_size: int,\n",
    "    scores_win: np.ndarray,\n",
    "    n_points: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Point score = max window score covering each point.\"\"\"\n",
    "    start_scores = np.full(n_points, np.nan, dtype=float)\n",
    "    for s, sc in zip(win_starts_local, scores_win):\n",
    "        s = int(s)\n",
    "        if 0 <= s < n_points:\n",
    "            start_scores[s] = float(sc)\n",
    "\n",
    "    from collections import deque\n",
    "    dq = deque()  # indices with decreasing scores\n",
    "\n",
    "    out = np.full(n_points, np.nan, dtype=float)\n",
    "    for i in range(n_points):\n",
    "        if i < n_points and not np.isnan(start_scores[i]):\n",
    "            while dq and start_scores[dq[-1]] <= start_scores[i]:\n",
    "                dq.pop()\n",
    "            dq.append(i)\n",
    "\n",
    "        left = i - win_size + 1\n",
    "        while dq and dq[0] < max(0, left):\n",
    "            dq.popleft()\n",
    "\n",
    "        out[i] = start_scores[dq[0]] if dq else np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_lstm_ae(window_size: int, lstm_units: int) -> tf.keras.Model:\n",
    "    \"\"\"Simple LSTM autoencoder.\"\"\"\n",
    "    inp = layers.Input(shape=(window_size, 1))\n",
    "    x = layers.LSTM(lstm_units, return_sequences=False)(inp)\n",
    "    x = layers.RepeatVector(window_size)(x)\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    out = layers.TimeDistributed(layers.Dense(1))(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "\n",
    "def reconstruction_mae(X: np.ndarray, X_hat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"MAE per window.\"\"\"\n",
    "    return np.mean(np.abs(X - X_hat), axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00406002-00a1-474e-a56c-1d6292b3bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - loss: 0.5037 - val_loss: 0.3010\n",
      "Epoch 2/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.2588 - val_loss: 0.1665\n",
      "Epoch 3/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1995 - val_loss: 0.1634\n",
      "Epoch 4/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1806 - val_loss: 0.1309\n",
      "Epoch 5/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1651 - val_loss: 0.1184\n",
      "Epoch 6/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1475 - val_loss: 0.1089\n",
      "Epoch 7/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1428 - val_loss: 0.1290\n",
      "Epoch 8/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1482 - val_loss: 0.1004\n",
      "Epoch 9/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1133 - val_loss: 0.0852\n",
      "Epoch 10/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1024 - val_loss: 0.0822\n",
      "Epoch 11/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0953 - val_loss: 0.0703\n",
      "Epoch 12/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0856 - val_loss: 0.0693\n",
      "Epoch 13/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0822 - val_loss: 0.0566\n",
      "Epoch 14/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0774 - val_loss: 0.0709\n",
      "Epoch 15/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0765 - val_loss: 0.0646\n",
      "Epoch 1/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.8762 - val_loss: 0.9152\n",
      "Epoch 2/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.8767 - val_loss: 0.9035\n",
      "Epoch 3/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8384 - val_loss: 0.8835\n",
      "Epoch 4/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8423 - val_loss: 0.8965\n",
      "Epoch 5/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8557 - val_loss: 0.8879\n",
      "Epoch 6/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8298 - val_loss: 0.8762\n",
      "Epoch 7/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8287 - val_loss: 0.8763\n",
      "Epoch 8/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.8284 - val_loss: 0.8996\n",
      "Epoch 9/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8370 - val_loss: 0.8738\n",
      "Epoch 10/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8250 - val_loss: 0.8740\n",
      "Epoch 11/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8282 - val_loss: 0.8710\n",
      "Epoch 12/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8300 - val_loss: 0.8784\n",
      "Epoch 13/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8334 - val_loss: 0.8693\n",
      "Epoch 14/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8207 - val_loss: 0.8725\n",
      "Epoch 15/15\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.8263 - val_loss: 0.8714\n",
      "Epoch 1/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.6073 - val_loss: 0.5732\n",
      "Epoch 2/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4346 - val_loss: 0.5495\n",
      "Epoch 3/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4580 - val_loss: 0.6719\n",
      "Epoch 4/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4343 - val_loss: 0.3660\n",
      "Epoch 5/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4538 - val_loss: 0.5222\n",
      "Epoch 6/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4636 - val_loss: 0.3678\n",
      "Epoch 7/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3902 - val_loss: 0.4090\n",
      "Epoch 8/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3388 - val_loss: 0.3565\n",
      "Epoch 9/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4081 - val_loss: 0.3928\n",
      "Epoch 10/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3321 - val_loss: 0.4056\n",
      "Epoch 11/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3626 - val_loss: 0.3582\n",
      "Epoch 12/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3095 - val_loss: 0.3175\n",
      "Epoch 13/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3130 - val_loss: 0.2707\n",
      "Epoch 14/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.3170 - val_loss: 0.2464\n",
      "Epoch 15/15\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.2725 - val_loss: 0.2013\n",
      "Epoch 1/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 0.8089 - val_loss: 0.7567\n",
      "Epoch 2/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7933 - val_loss: 0.7138\n",
      "Epoch 3/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7845 - val_loss: 0.6783\n",
      "Epoch 4/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7799 - val_loss: 0.6676\n",
      "Epoch 5/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7731 - val_loss: 0.6534\n",
      "Epoch 6/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7610 - val_loss: 0.6197\n",
      "Epoch 7/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7364 - val_loss: 0.5671\n",
      "Epoch 8/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6915 - val_loss: 0.5146\n",
      "Epoch 9/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6869 - val_loss: 0.5667\n",
      "Epoch 10/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6982 - val_loss: 0.7467\n",
      "Epoch 11/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6978 - val_loss: 0.5914\n",
      "Epoch 12/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6891 - val_loss: 0.7156\n",
      "Epoch 13/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8237 - val_loss: 0.6780\n",
      "Epoch 1/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.8341 - val_loss: 0.7522\n",
      "Epoch 2/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.8044 - val_loss: 0.6966\n",
      "Epoch 3/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7886 - val_loss: 0.6877\n",
      "Epoch 4/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7841 - val_loss: 0.6950\n",
      "Epoch 5/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7768 - val_loss: 0.6740\n",
      "Epoch 6/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7660 - val_loss: 0.6524\n",
      "Epoch 7/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7549 - val_loss: 0.6189\n",
      "Epoch 8/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7356 - val_loss: 0.5421\n",
      "Epoch 9/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7225 - val_loss: 0.5515\n",
      "Epoch 10/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7139 - val_loss: 0.5750\n",
      "Epoch 11/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7098 - val_loss: 0.6003\n",
      "Epoch 12/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7031 - val_loss: 0.5584\n",
      "Epoch 13/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6893 - val_loss: 0.5256\n",
      "Epoch 14/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6710 - val_loss: 0.5493\n",
      "Epoch 15/15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6625 - val_loss: 0.5290\n"
     ]
    }
   ],
   "source": [
    "# Main Execution Loop\n",
    "\n",
    "tf.random.set_seed(config.RANDOM_SEED)\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "\n",
    "base_out = results_dir(\"deep_learning\")\n",
    "csv_path = base_out / \"deep_learning_results.csv\"\n",
    "if csv_path.exists():\n",
    "    os.remove(csv_path)\n",
    "\n",
    "win_size = config.WINDOW_SIZE\n",
    "margin = config.PLOT_ZOOM_MARGIN\n",
    "\n",
    "ae_epochs = config.AE_PARAMS[\"epochs\"]\n",
    "ae_batch = config.AE_PARAMS[\"batch_size\"]\n",
    "ae_val = config.AE_PARAMS[\"validation_split\"]\n",
    "ae_patience = config.AE_PARAMS[\"early_stopping_patience\"]\n",
    "ae_units = config.AE_PARAMS[\"lstm_units\"]\n",
    "ae_clipnorm = config.AE_PARAMS[\"clipnorm\"]\n",
    "thr_q = config.AE_PARAMS[\"threshold_quantile\"]\n",
    "\n",
    "for dataset_name in config.DATASETS:\n",
    "    # Load point labels + split\n",
    "    _, labels, meta = load_cleaned(dataset_name)\n",
    "    train_end = int(meta[\"train_end\"])\n",
    "    y_test_point = labels[train_end:]\n",
    "\n",
    "    # Load method-ready\n",
    "    mr = load_method_ready(dataset_name)\n",
    "    train_z = mr[\"train_z\"]\n",
    "    test_z = mr[\"test_z\"]\n",
    "\n",
    "    train_starts = mr[\"train_win_starts\"]\n",
    "    test_starts_abs = mr[\"test_win_starts\"]\n",
    "    y_test_win = mr[\"test_win_labels\"]\n",
    "\n",
    "    # Convert test starts to local test coordinates\n",
    "    test_starts = test_starts_abs - train_end\n",
    "\n",
    "    # Build windows using the exact starts (no stride mismatch)\n",
    "    X_train = windows_from_starts(train_z, train_starts, win_size)\n",
    "    X_test = windows_from_starts(test_z, test_starts, win_size)\n",
    "\n",
    "    if len(X_test) != len(y_test_win):\n",
    "        raise ValueError(\n",
    "            f\"[{dataset_name}] Window alignment mismatch: \"\n",
    "            f\"X_test={len(X_test)} vs test_win_labels={len(y_test_win)}\"\n",
    "        )\n",
    "\n",
    "    out_dir = results_dir(\"deep_learning\", dataset_name)\n",
    "\n",
    "    # Overview plot (signal)\n",
    "    test_raw = mr[\"test_raw\"]\n",
    "    plot_signal(\n",
    "        test_raw,\n",
    "        true_labels=y_test_point,\n",
    "        title=f\"{dataset_name} - Test (overview)\",\n",
    "        save_path=out_dir / \"overview_signal.png\",\n",
    "        max_points=5000,\n",
    "    )\n",
    "\n",
    "    # Zoom window (test coords)\n",
    "    a0 = int(meta[\"anomaly_start\"]) - train_end\n",
    "    a1 = int(meta[\"anomaly_end\"]) - train_end\n",
    "    z0 = max(0, a0 - margin)\n",
    "    z1 = min(len(test_raw), a1 + margin)\n",
    "\n",
    "    # Model\n",
    "    model = build_lstm_ae(win_size, ae_units)\n",
    "    opt = tf.keras.optimizers.Adam(clipnorm=ae_clipnorm)\n",
    "    model.compile(optimizer=opt, loss=\"mae\")\n",
    "\n",
    "    cb = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=ae_patience, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train \n",
    "    model.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=ae_epochs,\n",
    "        batch_size=ae_batch,\n",
    "        validation_split=ae_val,\n",
    "        shuffle=False,\n",
    "        callbacks=cb,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Scores (window)\n",
    "    X_train_hat = model.predict(X_train, batch_size=ae_batch, verbose=0)\n",
    "    X_test_hat = model.predict(X_test, batch_size=ae_batch, verbose=0)\n",
    "\n",
    "    train_err = reconstruction_mae(X_train, X_train_hat)\n",
    "    test_err = reconstruction_mae(X_test, X_test_hat)\n",
    "\n",
    "    thr = float(np.quantile(train_err, thr_q))\n",
    "    pred_win = (test_err >= thr).astype(int)\n",
    "\n",
    "    # Window metrics (true window labels)\n",
    "    metrics_win = compute_binary_metrics(y_test_win, pred_win)\n",
    "\n",
    "    # Point scores/preds\n",
    "    score_point = windows_scores_to_point_scores_max(test_starts, win_size, test_err, len(test_raw))\n",
    "    pred_point = (np.nan_to_num(score_point, nan=-np.inf) >= thr).astype(int)\n",
    "    metrics_point = compute_binary_metrics(y_test_point, pred_point)\n",
    "\n",
    "    # Save\n",
    "    row = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"method\": \"lstm_ae\",\n",
    "        \"threshold\": thr,\n",
    "        \"thr_quantile\": thr_q,\n",
    "        **metrics_point,\n",
    "    }\n",
    "    append_csv_row(csv_path, row)\n",
    "\n",
    "    save_json(\n",
    "        out_dir / \"lstm_ae_metrics.json\",\n",
    "        {\n",
    "            **row,\n",
    "            \"window_metrics\": metrics_win,\n",
    "            \"n_train_windows\": int(len(X_train)),\n",
    "            \"n_test_windows\": int(len(X_test)),\n",
    "            \"ae_params\": config.AE_PARAMS,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    np.save(out_dir / \"lstm_ae_scores_win.npy\", test_err)\n",
    "    np.save(out_dir / \"lstm_ae_pred_win.npy\", pred_win)\n",
    "\n",
    "    np.save(out_dir / \"lstm_ae_scores.npy\", score_point)\n",
    "    np.save(out_dir / \"lstm_ae_pred.npy\", pred_point)\n",
    "\n",
    "    # Plots\n",
    "    plot_signal(\n",
    "        test_raw[z0:z1], y_test_point[z0:z1], pred_point[z0:z1],\n",
    "        title=f\"{dataset_name} - LSTM-AE (zoom)\",\n",
    "        save_path=out_dir / \"lstm_ae_signal_zoom.png\",\n",
    "        x_offset=z0,\n",
    "    )\n",
    "    plot_scores(\n",
    "        score_point[z0:z1],\n",
    "        threshold=thr,\n",
    "        true_labels=y_test_point[z0:z1],\n",
    "        title=f\"{dataset_name} - LSTM-AE scores (zoom)\",\n",
    "        save_path=out_dir / \"lstm_ae_scores_zoom.png\",\n",
    "        x_offset=z0,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BSP_Anomaly_Detection)",
   "language": "python",
   "name": "bsp-anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
